{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# install talib","metadata":{}},{"cell_type":"code","source":"# !cp ../input/talibinstall/ta-lib-0.4.0-src.tar.gzh  ./ta-lib-0.4.0-src.tar.gz\n# !tar -xzvf ta-lib-0.4.0-src.tar.gz > null\n# !cd ta-lib && ./configure --prefix=/usr > null && make  > null && make install > null\n# !cp ../input/talibinstall/TA-Lib-0.4.21.tar.gzh TA-Lib-0.4.21.tar.gz\n# !pip install TA-Lib-0.4.21.tar.gz > null\n# !pip install ../input/talibinstall/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl >null\n# import talib\n# talib.__version__","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:17.538228Z","iopub.execute_input":"2022-01-17T08:07:17.538701Z","iopub.status.idle":"2022-01-17T08:07:17.546152Z","shell.execute_reply.started":"2022-01-17T08:07:17.538573Z","shell.execute_reply":"2022-01-17T08:07:17.545426Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### メモリ削減","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:17.547716Z","iopub.execute_input":"2022-01-17T08:07:17.547941Z","iopub.status.idle":"2022-01-17T08:07:17.570738Z","shell.execute_reply.started":"2022-01-17T08:07:17.547907Z","shell.execute_reply":"2022-01-17T08:07:17.569836Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import psutil","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:17.572637Z","iopub.execute_input":"2022-01-17T08:07:17.572931Z","iopub.status.idle":"2022-01-17T08:07:17.582961Z","shell.execute_reply.started":"2022-01-17T08:07:17.572893Z","shell.execute_reply":"2022-01-17T08:07:17.582159Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量エンジニアリング","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport talib\nfrom sklearn.preprocessing import StandardScaler\nimport gc\n\nclass Feature():\n\n    def __init__(self) -> None:\n        pass\n    \n    def __del__(self):\n        \"\"\"オブジェクトが破棄されるとき呼び出される\"\"\"\n        print('Feature died:', id(self))\n\n    def conv_data(self, df, Asset_ID, df_list, save_fet=False, save_name='feature', save_mem=True, test=False):\n        \n        df.fillna(method='ffill', inplace=True)\n        \n        if not test:\n        \n            for i in range(13):\n                if not i == Asset_ID:\n                    as_df = df_list[i].copy()\n                    df[str(i)+'VWAP_shift105'] = as_df['VWAP'].shift(105) / as_df[\"VWAP\"]\n                    df[str(i)+'MOM'] = talib.MOM(as_df['Close'], timeperiod=176)\n\n                    del as_df\n                    gc.collect()\n\n            df['VWAP_shift15'] = df['VWAP'].shift(15) / df[\"VWAP\"]\n            df['VWAP_shift30'] = df['VWAP'].shift(30) / df[\"VWAP\"]\n            df['VWAP_shift45'] = df['VWAP'].shift(45) / df[\"VWAP\"]\n            df['VWAP_shift90'] = df['VWAP'].shift(90) / df[\"VWAP\"]\n            df['VWAP_shift120'] = df['VWAP'].shift(120) / df[\"VWAP\"]\n            df['VWAP_shift180'] = df['VWAP'].shift(180) / df[\"VWAP\"]\n            df['VWAP_shift210'] = df['VWAP'].shift(210) / df[\"VWAP\"]\n            df['VWAP_shift240'] = df['VWAP'].shift(240) / df[\"VWAP\"]\n            df['VWAP_shift310'] = df['VWAP'].shift(310) / df[\"VWAP\"]\n            df['VWAP_shift350'] = df['VWAP'].shift(350) / df[\"VWAP\"]\n            df['VWAP_shift400'] = df['VWAP'].shift(400) / df[\"VWAP\"]\n            df['VWAP_shift450'] = df['VWAP'].shift(450) / df[\"VWAP\"]\n            df['VWAP_shift550'] = df['VWAP'].shift(550) / df[\"VWAP\"]\n            df['VWAP_shift600'] = df['VWAP'].shift(600) / df[\"VWAP\"]\n            df['VWAP_shift650'] = df['VWAP'].shift(650) / df[\"VWAP\"]\n            df['VWAP_shift750'] = df['VWAP'].shift(750) / df[\"VWAP\"]\n            df['VWAP_shift800'] = df['VWAP'].shift(800) / df[\"VWAP\"]\n            df['VWAP_shift1000'] = df['VWAP'].shift(1000) / df[\"VWAP\"]\n            df['VWAP_shift1500'] = df['VWAP'].shift(1500) / df[\"VWAP\"]\n            df['VWAP_shift2000'] = df['VWAP'].shift(2000) / df[\"VWAP\"]\n            df['VWAP_shift2500'] = df['VWAP'].shift(2500) / df[\"VWAP\"]\n            df['VWAP_shift3000'] = df['VWAP'].shift(3000) / df[\"VWAP\"]\n            df['VWAP_shift3500'] = df['VWAP'].shift(3500) / df[\"VWAP\"]\n            df['VWAP_shift4000'] = df['VWAP'].shift(4000) / df[\"VWAP\"]\n            df['VWAP_shift4500'] = df['VWAP'].shift(4500) / df[\"VWAP\"]\n            df['VWAP_shift5000'] = df['VWAP'].shift(5000) / df[\"VWAP\"]\n            df['VWAP_shift5500'] = df['VWAP'].shift(5500) / df[\"VWAP\"]\n            df['VWAP_shift6000'] = df['VWAP'].shift(6000) / df[\"VWAP\"]\n            df['VWAP_shift7000'] = df['VWAP'].shift(7000) / df[\"VWAP\"]\n            df['VWAP_shift8000'] = df['VWAP'].shift(8000) / df[\"VWAP\"]\n            df['VWAP_shift9000'] = df['VWAP'].shift(9000) / df[\"VWAP\"]\n            df['VWAP_shift10000'] = df['VWAP'].shift(10000) / df[\"VWAP\"]\n            df['VWAP_shift11000'] = df['VWAP'].shift(11000) / df[\"VWAP\"]\n            df['VWAP_shift12000'] = df['VWAP'].shift(12000) / df[\"VWAP\"]\n            df['VWAP_shift14000'] = df['VWAP'].shift(14000) / df[\"VWAP\"]\n            df['VWAP_shift16000'] = df['VWAP'].shift(16000) / df[\"VWAP\"]\n            df['VWAP_shift18000'] = df['VWAP'].shift(18000) / df[\"VWAP\"]\n            df['VWAP_shift25000'] = df['VWAP'].shift(25000) / df[\"VWAP\"]\n            df['Volume_shift_sma2000'] = (df['Volume'].rolling(2000).sum() / df[\"Volume\"]).apply(np.log)\n            df['Close_shift70'] = df['Close'].shift(70) / df[\"Close\"]\n            df['Close_shift280'] = df['Close'].shift(280) / df[\"Close\"]\n            df['SMA_18000_std'] = df['Close'].rolling(18000).std().shift() / df['Close']\n            df['ROCP'] = talib.ROCP(df['Close'], timeperiod=181)\n            df['MOM'] = talib.MOM(df['Close'], timeperiod=176)\n            df['MOM_1700'] = talib.MOM(df['Close'], timeperiod=1760)\n            df['RSI'] = talib.RSI(df['Close'], timeperiod=206)\n            df['EMA'] = (talib.EMA(df['Close'], timeperiod=11) - df['Close']) / df[\"Close\"]\n            df['APO'] = talib.APO(df['Close'], fastperiod=117, slowperiod=166, matype=0)\n            df['CMO'] = talib.CMO(df['Close'], timeperiod=204)\n            macd, macdsignal, macdhist = talib.MACD(df['Close'], fastperiod=324, slowperiod=296, signalperiod=272)\n            df['macdhist0'] = macdhist\n            df['macdhist1'] = macdhist.shift(1)\n            df['macdhist5'] = macdhist.shift(5)\n            df['macdhist15'] = macdhist.shift(15)\n            df['ADX'] = talib.ADX(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=181)\n            df['AD'] = talib.AD(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"])\n            df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df[\"Close\"], timeperiod=181)\n            df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df[\"Close\"])\n            df['NATR'] = talib.NATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=181)\n            df['AROONOSC'] = talib.AROONOSC(df[\"High\"], df[\"Low\"], timeperiod=181)\n            aroondown, aroonup = talib.AROON(df[\"High\"], df[\"Low\"], timeperiod=181)\n            df['aroondown'] = aroondown\n            df['aroonup'] = aroonup\n            df['PLUS_DI'] = talib.PLUS_DI(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=181)\n            upper1, middle,lower1 = talib.BBANDS(df[\"Close\"], timeperiod=181, nbdevup=3, nbdevdn=3, matype=0)\n            df['BBANDS'] = (upper1 - df['Close']).apply(np.log)\n            df['CDL2CROWS'] = talib.CDL2CROWS(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n\n            categorical_features = ['CDL2CROWS']\n            \n            delete_columns = ['Asset_ID','High','Low','Close','Open','VWAP','Volume','Count']\n            #df.drop(delete_columns, axis=1, inplace=True)\n            for colum in delete_columns:\n                del df[colum]; gc.collect();\n                \n            df.reset_index(drop=True, inplace=True)\n        else:\n            \n            cols = []\n            for i in range(13):\n                if not i == Asset_ID:\n                    cols.append(str(i)+'VWAP_shift105')\n                    cols.append(str(i)+'MOM')\n            cols.extend(['VWAP_shift15','VWAP_shift30','VWAP_shift45','VWAP_shift90','VWAP_shift120','VWAP_shift180','VWAP_shift210','VWAP_shift240','VWAP_shift310','VWAP_shift350','VWAP_shift400','VWAP_shift450','VWAP_shift550','VWAP_shift600','VWAP_shift650','VWAP_shift750','VWAP_shift800','VWAP_shift1000','VWAP_shift1500','VWAP_shift2000','VWAP_shift2500','VWAP_shift3000','VWAP_shift3500','VWAP_shift4000','VWAP_shift4500','VWAP_shift5000','VWAP_shift5500','VWAP_shift6000','VWAP_shift7000','VWAP_shift8000','VWAP_shift9000','VWAP_shift10000','VWAP_shift11000','VWAP_shift12000','VWAP_shift14000','VWAP_shift16000','VWAP_shift18000','VWAP_shift25000','Volume_shift_sma2000','Close_shift70','Close_shift280','SMA_18000_std','ROCP','MOM','MOM_1700','RSI','EMA','APO','CMO','macdhist0','macdhist1','macdhist5','macdhist15','ADX','AD','LINEARREG_ANGLE','HT_DCPERIOD','NATR','AROONOSC','aroondown','aroonup','PLUS_DI','BBANDS','CDL2CROWS'])\n            ans = pd.DataFrame(index=[0], columns=cols)\n            \n            start = time.time()\n            for i in range(13):\n                if not i == Asset_ID:\n                    as_df = df_list[i].copy()\n                    ans[str(i)+'VWAP_shift105'] = as_df.iloc[-106,7] / as_df.iloc[-1,7]\n                    ans[str(i)+'MOM'] = talib.MOM(as_df.iloc[-177:,5], timeperiod=176).iloc[-1]\n            print (\"1.0elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n\n            start = time.time()\n            ans['VWAP_shift15'] = df.iloc[-16,7] / df.iloc[-1,7]\n            ans['VWAP_shift30'] = df.iloc[-31,7] / df.iloc[-1,7]\n            ans['VWAP_shift45'] = df.iloc[-46,7] / df.iloc[-1,7]\n            ans['VWAP_shift90'] = df.iloc[-91,7] / df.iloc[-1,7]\n            ans['VWAP_shift120'] = df.iloc[-121,7] / df.iloc[-1,7]\n            ans['VWAP_shift180'] = df.iloc[-181,7] / df.iloc[-1,7]\n            ans['VWAP_shift210'] = df.iloc[-211,7] / df.iloc[-1,7]\n            ans['VWAP_shift240'] = df.iloc[-241,7] / df.iloc[-1,7]\n            ans['VWAP_shift310'] = df.iloc[-311,7] / df.iloc[-1,7]\n            ans['VWAP_shift350'] = df.iloc[-351,7] / df.iloc[-1,7]\n            ans['VWAP_shift400'] = df.iloc[-401,7] / df.iloc[-1,7]\n            ans['VWAP_shift450'] = df.iloc[-451,7] / df.iloc[-1,7]\n            ans['VWAP_shift550'] = df.iloc[-551,7] / df.iloc[-1,7]\n            ans['VWAP_shift600'] = df.iloc[-601,7] / df.iloc[-1,7]\n            ans['VWAP_shift650'] = df.iloc[-651,7] / df.iloc[-1,7]\n            ans['VWAP_shift750'] = df.iloc[-751,7] / df.iloc[-1,7]\n            ans['VWAP_shift800'] = df.iloc[-801,7] / df.iloc[-1,7]\n            ans['VWAP_shift1000'] = df.iloc[-1001,7] / df.iloc[-1,7]\n            ans['VWAP_shift1500'] = df.iloc[-1501,7] / df.iloc[-1,7]\n            ans['VWAP_shift2000'] = df.iloc[-2001,7] / df.iloc[-1,7]\n            ans['VWAP_shift2500'] = df.iloc[-2501,7] / df.iloc[-1,7]\n            ans['VWAP_shift3000'] = df.iloc[-3001,7] / df.iloc[-1,7]\n            ans['VWAP_shift3500'] = df.iloc[-3501,7] / df.iloc[-1,7]\n            ans['VWAP_shift4000'] = df.iloc[-4001,7] / df.iloc[-1,7]\n            ans['VWAP_shift4500'] = df.iloc[-4501,7] / df.iloc[-1,7]\n            ans['VWAP_shift5000'] = df.iloc[-5001,7] / df.iloc[-1,7]\n            ans['VWAP_shift5500'] = df.iloc[-5501,7] / df.iloc[-1,7]\n            ans['VWAP_shift6000'] = df.iloc[-6001,7] / df.iloc[-1,7]\n            ans['VWAP_shift7000'] = df.iloc[-7001,7] / df.iloc[-1,7]\n            ans['VWAP_shift8000'] = df.iloc[-8001,7] / df.iloc[-1,7]\n            ans['VWAP_shift9000'] = df.iloc[-9001,7] / df.iloc[-1,7]\n            ans['VWAP_shift10000'] = df.iloc[-10001,7] / df.iloc[-1,7]\n            ans['VWAP_shift11000'] = df.iloc[-11001,7] / df.iloc[-1,7]\n            ans['VWAP_shift12000'] = df.iloc[-12001,7] / df.iloc[-1,7]\n            ans['VWAP_shift14000'] = df.iloc[-14001,7] / df.iloc[-1,7]\n            ans['VWAP_shift16000'] = df.iloc[-16001,7] / df.iloc[-1,7]\n            ans['VWAP_shift18000'] = df.iloc[-18001,7] / df.iloc[-1,7]\n            ans['VWAP_shift25000'] = df.iloc[-25001,7] / df.iloc[-1,7]\n            print (\"1.1elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n            start = time.time()\n            ans['Volume_shift_sma2000'] = (df['Volume'].rolling(2000).sum() / df[\"Volume\"]).apply(np.log).iloc[-1]\n            ans['Close_shift70'] = df.iloc[-71,5] / df.iloc[-1,5]\n            ans['Close_shift280'] = df.iloc[-281,5] / df.iloc[-1,5]\n            ans['SMA_18000_std'] = df['Close'].rolling(18000).std().shift() / df.iloc[:,5]\n            ans['ROCP'] = talib.ROCP(df.iloc[-182:,5], timeperiod=181).iloc[-1]\n            ans['MOM'] = talib.MOM(df.iloc[-177:,5], timeperiod=176).iloc[-1]\n            ans['MOM_1700'] = talib.MOM(df.iloc[-1761:,5], timeperiod=1760).iloc[-1]\n            ans['RSI'] = talib.RSI(df.iloc[-207:,5], timeperiod=206).iloc[-1]\n            ans['EMA'] = (talib.EMA(df.iloc[-12:,5], timeperiod=11).iloc[-1] - df.iloc[-1,5]) / df.iloc[-1,5]\n            ans['APO'] = talib.APO(df.iloc[-167:,5], fastperiod=117, slowperiod=166, matype=0).iloc[-1]\n            ans['CMO'] = talib.CMO(df.iloc[-205:,5], timeperiod=204).iloc[-1]\n            macd, macdsignal, macdhist = talib.MACD(df.iloc[-610:,5], fastperiod=324, slowperiod=296, signalperiod=272)\n            ans['macdhist0'] = macdhist.iloc[-1]\n            ans['macdhist1'] = macdhist.iloc[-2]\n            ans['macdhist5'] = macdhist.iloc[-6]\n            ans['macdhist15'] = macdhist.iloc[-16]\n            ans['ADX'] = talib.ADX(df.iloc[-362:,3], df.iloc[-362:,4], df.iloc[-362:,5], timeperiod=181).iloc[-1]\n            ans['AD'] = talib.AD(df.iloc[-2:,3], df.iloc[-2:,4], df.iloc[-2:,5], df.iloc[-2:,6]).iloc[-1]\n            ans['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df.iloc[-182:,5], timeperiod=181).iloc[-1]\n            ans['HT_DCPERIOD'] = talib.HT_DCPERIOD(df.iloc[-1000:,5]).iloc[-1]\n            ans['NATR'] = talib.NATR(df.iloc[-182:,3], df.iloc[-182:,4], df.iloc[-182:,5], timeperiod=181).iloc[-1]\n            ans['AROONOSC'] = talib.AROONOSC(df.iloc[-182:,3], df.iloc[-182:,4], timeperiod=181).iloc[-1]\n            aroondown, aroonup = talib.AROON(df.iloc[-182:,3], df.iloc[-182:,4], timeperiod=181)\n            ans['aroondown'] = aroondown.iloc[-1]\n            ans['aroonup'] = aroonup.iloc[-1]\n            ans['PLUS_DI'] = talib.PLUS_DI(df.iloc[-182:,3], df.iloc[-182:,4], df.iloc[-182:,5], timeperiod=181).iloc[-1]\n            upper1, middle,lower1 = talib.BBANDS(df.iloc[-182:,5], timeperiod=181, nbdevup=3, nbdevdn=3, matype=0)\n            ans['BBANDS'] = (upper1.iloc[-2:] - df.iloc[-2:,5]).apply(np.log).iloc[-1]\n\n            ans['CDL2CROWS'] = talib.CDL2CROWS(df.iloc[-1000:,2], df.iloc[-1000:,3], df.iloc[-1000:,4], df.iloc[-1000:,5]).iloc[-1]\n            categorical_features = ['CDL2CROWS']\n            \n            #print(ans.info())################################\n            \n            df = ans.copy()\n            print (\"1.2elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n            \n        start = time.time()\n        \n        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n        df.fillna(method='ffill', inplace=True)\n        df.fillna(0, inplace=True)\n        \n        dfX = df.copy()\n        dfX.drop(categorical_features, axis=1, inplace=True)\n        columns = dfX.columns.tolist()\n        X = dfX.values\n        if not test:\n            del dfX\n            gc.collect()\n        \"\"\"正規化 sklearn\n        scaler = StandardScaler()\n        scaler.fit(X)\n        X = scaler.transform(X)\"\"\"\n        \n        print (\"1.3elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n        start = time.time()\n        \n        mean_n = [[ 9.99885373e-01,  3.09758273e-02,  1.00018938e+00, -1.61865578e-01,\n                   9.21656800e-01,  1.65773236e-04,  6.56436859e-01,  1.86611370e-05,\n                   1.00013456e+00, -2.89830662e-04,  9.99977581e-01,  2.04807467e-01,\n                   1.00009365e+00,  2.15764428e-03,  9.05655877e-01, -9.88395078e-05,\n                   1.00009076e+00, -5.51462303e-03,  9.10990142e-01, -1.16363673e+01,\n                   1.00010193e+00, -1.56828965e-02,  9.65466065e-01, -6.98199983e-05,\n                   9.99993611e-01,  9.99986900e-01,  9.99979881e-01,  9.99957910e-01,\n                   9.99942407e-01,  9.99909481e-01,  9.99893581e-01,  9.99877334e-01,\n                   9.99838662e-01,  9.99816700e-01,  9.99788575e-01,  9.99761023e-01,\n                   9.99704426e-01,  9.99676509e-01,  9.99649796e-01,  9.99595992e-01,\n                   9.99569505e-01,  9.99468803e-01,  9.99220890e-01,  9.98908461e-01,\n                   9.98604001e-01,  9.98327831e-01,  9.98046306e-01,  9.97759143e-01,\n                   9.97491716e-01,  9.97218832e-01,  9.96945641e-01,  9.96689312e-01,\n                   9.96208285e-01,  9.95795422e-01,  9.95385685e-01,  9.95037603e-01,\n                   9.94681685e-01,  9.94254386e-01,  9.93227183e-01,  9.92229041e-01,\n                   9.91203069e-01,  9.87183158e-01,  7.96081342e+00,  9.99967919e-01,\n                   9.99854823e-01,  4.95978312e-02,  2.16599492e-04,  2.68893869e+00,\n                   2.84985841e+01,  5.01774243e+01,  5.11677265e-07,  3.75372870e-01,\n                   3.66093910e-01, -1.06804469e-03, -1.06421319e-03, -1.04921838e-03,\n                  -1.01535536e-03,  1.73946113e+01, -6.55988342e+06,  8.84185123e-01,\n                   2.13108282e+01,  7.92234250e-01,  2.13442151e+00,  4.46625790e+01,\n                   4.67970006e+01,  7.52846011e+00,  4.47998655e+00]]\n            \n            \n        std_n = [[1.83716857e-02, 3.89781053e+00, 1.95957894e-02, 1.74106538e+01,\n                  2.69214360e-01, 1.68087136e-02, 4.75186737e-01, 4.54993587e-03,\n                  1.95644498e-02, 1.67338689e-01, 1.63526168e-02, 2.37303288e+01,\n                  2.08237552e-02, 8.69332369e-01, 2.93120932e-01, 2.00583700e-02,\n                  1.75618881e-02, 2.86042554e+00, 3.37676176e-01, 8.20031691e+01,\n                  1.87165419e-02, 4.14204761e+00, 1.84251487e-01, 6.56426652e-03,\n                  5.26436091e-03, 7.40879647e-03, 9.02836838e-03, 1.26595499e-02,\n                  1.45492033e-02, 1.76408183e-02, 1.90177510e-02, 2.02852605e-02,\n                  2.29294077e-02, 2.43220605e-02, 2.59342450e-02, 2.74509028e-02,\n                  3.02354843e-02, 3.15529478e-02, 3.28535234e-02, 3.53239890e-02,\n                  3.65483469e-02, 4.12821836e-02, 5.13174474e-02, 5.86539714e-02,\n                  6.52650303e-02, 7.14069839e-02, 7.69020650e-02, 8.20182956e-02,\n                  8.69482487e-02, 9.15959641e-02, 9.61233061e-02, 1.00670713e-01,\n                  1.09340057e-01, 1.17680116e-01, 1.25375445e-01, 1.33253465e-01,\n                  1.40662143e-01, 1.47272021e-01, 1.58726547e-01, 1.69942399e-01,\n                  1.79984757e-01, 2.12667894e-01, 8.42835655e-01, 1.12048392e-02,\n                  2.18179046e-02, 3.50607903e-02, 1.47249468e-02, 3.38298633e+02,\n                  1.02971586e+03, 3.29244781e+00, 1.76477768e-03, 5.60760509e+01,\n                  6.53106150e+00, 6.53123593e+00, 6.53123373e+00, 6.53122532e+00,\n                  6.53120810e+00, 1.57331750e+01, 4.61154350e+06, 3.59955260e+01,\n                  5.35233709e+00, 1.04905727e+00, 5.59595607e+01, 3.31159638e+01,\n                  3.37248055e+01, 4.47656604e+00, 1.38126899e+00]]\n        \n        #mean_n = X.mean(axis = 0, keepdims = True)\n        #標準偏差を計算 ddof=0なら標準偏差、ddof=1なら不偏標準偏差\n        #std_n = X.std(axis = 0, keepdims = True, ddof = 0)\n        #標準化の計算\n        X = (X - mean_n) / std_n\n        \n        df = pd.concat([pd.DataFrame(X, columns=columns), df[categorical_features]], axis=1)\n\n        if save_fet:\n            df.to_csv(save_name+'.csv', index=False)\n            \n        if save_mem:\n            df = reduce_mem_usage(df)\n        \n        if not test:\n            del df_list, X\n            gc.collect()\n        print (\"1.4elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n\n        return df\n    \n    def normalize(self, df):\n        return (df - df.mean()) / df.std(ddof=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:17.584981Z","iopub.execute_input":"2022-01-17T08:07:17.586159Z","iopub.status.idle":"2022-01-17T08:07:18.338876Z","shell.execute_reply.started":"2022-01-17T08:07:17.585971Z","shell.execute_reply":"2022-01-17T08:07:18.338180Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Util","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\nclass Util():\n\n    def __init__(self) -> None:\n        pass\n\n    def data_conv(self, data):\n        #data = (data > 0.5).astype(int)\n        return data\n\n\n    def accuracy_score(self, train, predict):\n        \"\"\"\n        どのくらい答えに近いか評価するスコアを出す\n        あっているほど数値が高いようにする\n        コンペによって評価方法が違うからこれを変える\n        \"\"\"\n        #ピアソンの相関係数\n        return np.corrcoef(train,predict)[0,1]","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:18.342342Z","iopub.execute_input":"2022-01-17T08:07:18.342629Z","iopub.status.idle":"2022-01-17T08:07:18.370693Z","shell.execute_reply.started":"2022-01-17T08:07:18.342590Z","shell.execute_reply":"2022-01-17T08:07:18.369973Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# モデル","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import ElasticNet\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom catboost import Pool\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pandas as pd\nimport pickle\n\nfrom memory_profiler import profile\nimport gc\n\n\nut = Util()\n\nclass Models:\n    def __init__(self,ID) -> None:\n        fileID = ID\n        self.models_xgboost = []\n        for fold_id in range(4):\n            try:\n                with open('xgboost'+str(fileID)+'0'+str(fold_id)+'.pickle', 'rb') as web:\n                    self.models_xgboost.append(pickle.load(web))\n                #print('load')\n            except FileNotFoundError:\n                #print('Not find '+str(fileID)+'0'+str(fold_id))\n                pass\n    \n    def __del__(self):\n        \"\"\"オブジェクトが破棄されるとき呼び出される\"\"\"\n        print('Models died:', id(self))\n\n    def select_model(self, categorical_features, model_name, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None):\n        if model_name == \"random_forest\":\n            score, y_val_pre, y_pred = self.random_forest(learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        elif model_name == \"light_gbm\":\n            score, y_val_pre, y_pred = self.light_gbm(categorical_features, learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        elif model_name == 'xgboost':\n            score, y_val_pre, y_pred = self.xgboost(learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        elif model_name == \"catboost\":\n            score, y_val_pre, y_pred = self.catboost(categorical_features, learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        elif model_name == \"logistic_regression\":\n            score, y_val_pre, y_pred = self.logistic_regression(learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        elif model_name == \"dnn\":\n            score, y_val_pre, y_pred = self.dnn(learn_type, fileID=fileID, X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, X_test=X_test)\n        else:\n            raise NameError(\"指定されたアルゴリズムは存在しません\")\n            \n\n        return score, y_val_pre, y_pred\n    \n    def KFold(self, categorical_features, model_name, learn_type, fileID=0, X_train=None, y_train=None, X_test=None, n_splits=4):\n\n        cv_score, oof_pre, y_sub = None, None, None\n        scores = []\n        oof_pre = np.array([])\n        valid_indexs = np.array([])\n        y_preds = []\n        cv = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n        if learn_type=='learn':\n            for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, y_train)):\n                X_tr = X_train.loc[train_index, :]\n                X_val = X_train.loc[valid_index, :]\n                y_tr = y_train[train_index]\n                y_val = y_train[valid_index]\n\n                score, y_val_pre, _ = self.select_model(categorical_features, model_name, 'learn', fileID=str(fileID)+str(fold_id),X_train=X_tr, y_train=y_tr, X_valid=X_val, y_valid=y_val)\n\n                scores.append(score)\n                oof_pre = np.append(oof_pre,y_val_pre)\n                valid_indexs = np.append(valid_indexs, valid_index)\n\n            oof_pre = oof_pre[np.argsort(valid_indexs)]\n            cv_score = sum(scores) / len(scores)\n        elif learn_type=='predict':\n            for fold_id in range(n_splits):\n                score, y_val_pre, y_pred = self.select_model(categorical_features, model_name, 'predict', fileID=str(fileID)+str(fold_id), X_test=X_test)\n                oof_pre = np.append(oof_pre,y_val_pre)\n                y_preds.append(y_pred)\n            \n            y_sub = sum(y_preds) / len(y_preds)\n\n        return cv_score, oof_pre, y_sub\n\n    def random_forest(self, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None, n_estimators=67, max_depth=6, random_state=0):\n        \"\"\"\n        pandasでの教師データ\n        パラメータ\n        return valスコア(float)、その取り出し方での予測値\n        \"\"\"\n        print('========random_forest========')\n        score, y_val_pre, y_pred = None, None, None\n        if learn_type=='predict':\n            with open('RandomForest'+str(fileID)+'.pickle', 'rb') as web:\n                RandomForest = pickle.load(web)\n            y_pred = RandomForest.predict(X_test)\n        elif learn_type=='learn':\n            #RandomForest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n            RandomForest = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n            RandomForest.fit(X_train, y_train)\n            y_val_pre = RandomForest.predict(X_valid)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            with open('RandomForest'+str(fileID)+'.pickle', 'wb') as web:\n                pickle.dump(RandomForest , web)\n\n        return score, y_val_pre, y_pred\n\n    def light_gbm(self, categorical_features, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None, params = {'objective': 'binary','max_bin': 284,'learning_rate': 0.068,'num_leaves': 45}):\n        \"\"\"\n        pandasでの教師データ\n        categorical_features:カテゴリかる属性のカラム名を示したリスト\n        パラメータ\n        return valスコア(float), y_val_pre(valでの予測値), その取り出し方での予測値\n        \"\"\"\n        print('========light_gbm========')\n        score, y_val_pre, y_pred = None, None, None\n        if learn_type=='predict':\n            with open('light_gbm'+str(fileID)+'.pickle', 'rb') as web:\n                model = pickle.load(web)\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n            y_pred = ut.data_conv(y_pred)\n        elif learn_type=='learn':\n            lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n            lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n            model = lgb.train(params, lgb_train,valid_sets=[lgb_train, lgb_eval],verbose_eval=10,num_boost_round=1000,early_stopping_rounds=10)\n\n            y_val_pre = model.predict(X_valid, num_iteration=model.best_iteration)\n            y_val_pre = ut.data_conv(y_val_pre)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            with open('light_gbm'+str(fileID)+'.pickle', 'wb') as web:\n                pickle.dump(model , web)\n\n        return score, y_val_pre, y_pred\n    \n    def xgboost(self, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None, params = {'tree_method': 'gpu_hist', 'objective': 'reg:squarederror','silent':1, 'random_state':0,'learning_rate': 0.15, 'eval_metric': 'rmse',}, num_round = 450):\n        \"\"\"\n        pandasでの教師データ\n        categorical_features:カテゴリかる属性のカラム名を示したリスト\n        パラメータ\n        return valスコア(float), y_val_pre(valでの予測値), その取り出し方での予測値\n        \"\"\"\n        score, y_val_pre, y_pred = None, None, None\n        if learn_type=='predict':\n            test = xgb.DMatrix(X_test)\n            model = self.models_xgboost[int(str(fileID)[-1])]\n            y_pred = model.predict(test)\n        elif learn_type=='learn':\n            print('========xgboost========')\n            train = xgb.DMatrix(X_train, label=y_train)\n            valid = xgb.DMatrix(X_valid, label=y_valid)\n            self.model_xgboost = xgb.train(params,\n                    train,#訓練データ\n                    num_round,#設定した学習回数\n                    early_stopping_rounds=20,\n                    evals=[(train, 'train'), (valid, 'eval')],\n                    verbose_eval=100\n                    )\n            y_val_pre = self.model_xgboost.predict(valid)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            with open('xgboost'+str(fileID)+'.pickle', 'wb') as web:\n                pickle.dump(self.model_xgboost, web)\n                \n        \n        \n#         _, ax = plt.subplots(figsize=(12, 15))\n#         xgb.plot_importance(model,\n#                     ax=ax,\n#                     importance_type='gain',\n#                     show_values=False)\n#         plt.show()\n        \n        \n        return score, y_val_pre, y_pred\n\n    def catboost(self, categorical_features, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None, params ={'depth' : 3,'learning_rate' : 0.054,'early_stopping_rounds' : 9,'iterations' : 474, 'loss_function' : 'RMSE', 'random_seed' :0}):\n        \"\"\"\n        pandasでの教師データ\n        categorical_features:カテゴリかる属性のカラム名を示したリスト\n        パラメータ\n        return valスコア(float), y_val_pre(valでの予測値), その取り出し方での予測値\n        \"\"\"\n        print('========catboost========')\n        score, y_val_pre, y_pred = None, None, None\n        if learn_type=='predict':\n            with open('catboost'+str(fileID)+'.pickle', 'rb') as web:\n                model = pickle.load(web)\n            y_pred = model.predict(X_test)\n            y_pred = ut.data_conv(y_pred)\n        elif learn_type=='learn':\n            train = Pool(X_train, y_train, cat_features=categorical_features)\n            eval = Pool(X_valid, y_valid, cat_features=categorical_features)\n            #cab = CatBoostClassifier(custom_loss=['Accuracy'],random_seed=0)\n            #cab = CatBoostClassifier(**params)\n            cab = CatBoostRegressor(random_seed=0)\n            cab = CatBoostRegressor(**params)\n            model = cab.fit(train, eval_set=eval)\n\n            y_val_pre = model.predict(X_valid)\n            y_val_pre = ut.data_conv(y_val_pre)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            with open('catboost'+str(fileID)+'.pickle', 'wb') as web:\n                pickle.dump(model , web)\n\n        return score, y_val_pre, y_pred\n\n    def logistic_regression(self, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None):\n        \"\"\"\n        pandasでの教師データ\n        パラメータ\n        return valスコア(float)、その取り出し方での予測値\n        \"\"\"\n        print('========logistic_regression========')\n        score, y_val_pre, y_pred = None, None, None\n        if learn_type=='predict':\n            with open('logistic_regression'+str(fileID)+'.pickle', 'rb') as web:\n                model = pickle.load(web)\n            y_pred = model.predict(X_test)\n            y_pred = ut.data_conv(y_pred)\n        elif learn_type=='learn':\n            #model = LogisticRegression(penalty='l2', solver='sag', random_state=0)\n            model = ElasticNet(random_state=0)\n            model.fit(X_train, y_train)\n            y_val_pre = model.predict(X_valid)\n            y_val_pre = ut.data_conv(y_val_pre)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            with open('logistic_regression'+str(fileID)+'.pickle', 'wb') as web:\n                pickle.dump(model , web)\n\n        return score, y_val_pre, y_pred\n\n    def dnn(self, learn_type, fileID=0, X_train=None, y_train=None, X_valid=None, y_valid=None, X_test=None):\n        \n        print('========dnn========')\n        score, y_val_pre, y_pred = None, None, None\n\n        lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay( \\\n                    initial_learning_rate=0.001, #初期の学習率\n                    decay_steps=3, #減衰ステップ数\n                    decay_rate=0.01, #最終的な減衰率 \n                    staircase=True)\n\n        model=Sequential()\n        model.add(Dense(len(X_train.columns),input_shape=(len(X_train.columns),),activation='relu',\n                    kernel_regularizer=keras.regularizers.l2(0.001), #重みの正則化考慮\n                    kernel_initializer='random_uniform',\n                    bias_initializer='zero'))\n                    \n        model.add(BatchNormalization()) #バッチ正規化\n        model.add(Dropout(0.1)) # ドロップアウト層・ドロップアウトさせる割合\n        model.add(Dense(int(len(pd.DataFrame(X_train).columns)/2),activation='sigmoid'))\n\n        model.add(BatchNormalization()) #バッチ正規化\n        model.add(Dropout(0.1)) # ドロップアウト層・ドロップアウトさせる割合\n        model.add(Dense(int(len(pd.DataFrame(X_train).columns)/2),activation='sigmoid'))\n\n        model.add(BatchNormalization()) #バッチ正規化\n        model.add(Dropout(0.1)) # ドロップアウト層・ドロップアウトさせる割合\n        model.add(Dense(len(pd.DataFrame(y_train).columns),activation='sigmoid'))\n        Ecall=EarlyStopping(monitor='val_loss',patience=1000,restore_best_weights=False)\n        model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr_schedule))\n        model.summary()\n\n        if learn_type=='predict':\n            model.load_weights('dnn'+str(fileID)+'.h5')\n            y_pred = model.predict(X_test)\n            y_pred = ut.data_conv(y_pred)\n        elif learn_type=='learn':\n            res=model.fit(X_train.values,y_train.values,epochs=3,callbacks=[Ecall],verbose=1,validation_data=(X_valid.values,y_valid.values))\n            y_val_pre = model.predict(X_valid)[:,0]\n            y_val_pre = ut.data_conv(y_val_pre)\n            print(y_valid.shape)\n            print(y_val_pre.shape)\n            score = ut.accuracy_score(y_valid, y_val_pre)\n            model.save_weights('dnn'+str(fileID)+'.h5')\n\n        return score, y_val_pre, y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:18.372479Z","iopub.execute_input":"2022-01-17T08:07:18.372732Z","iopub.status.idle":"2022-01-17T08:07:22.815523Z","shell.execute_reply.started":"2022-01-17T08:07:18.372697Z","shell.execute_reply":"2022-01-17T08:07:22.814726Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# パラメータオプティマイザー","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport optuna\nfrom sklearn.metrics import log_loss\n\n#md = Models(0)\n\n#random_forest : {'n_estimators': 67, 'max_depth': 6}\n#light_gbm : {'max_bin': 284, 'learning_rate': 0.06759289191947715, 'num_leaves': 45}\n#xgboost : {'learning_rate': 0.180343853211702, 'num_round': 394}\n#catboost : {'depth': 3, 'learning_rate': 0.053925065258405916, 'early_stopping_rounds': 9, 'iterations': 474}\nclass Optimizer():\n    def __init__(self) -> None:\n        pass\n\n    def param_opt(self, model_name, X_train, y_train, categorical_features=None):\n        \"\"\"\n        パラメータオプティマイザー\n        model name list: random_forest, light_gbm\n        \"\"\"\n        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3,random_state=0, stratify=y_train)\n        study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n        if model_name == \"random_forest\":\n            study.optimize(self.objective_random_forest(X_train, y_train, X_valid, y_valid), n_trials=80)\n            return study.best_params\n\n        elif model_name == \"light_gbm\":\n            study.optimize(self.objective_light_gbm(X_train, y_train, X_valid, y_valid, categorical_features), n_trials=80)\n            return study.best_params\n\n        elif model_name == \"xgboost\":\n            study.optimize(self.objective_xgboost(X_train, y_train, X_valid, y_valid), n_trials=80)\n            return study.best_params\n\n        elif model_name == \"catboost\":\n            study.optimize(self.objective_catboost(X_train, y_train, X_valid, y_valid, categorical_features), n_trials=80)\n            return study.best_params\n            \n        elif model_name == 'logistic_regression':\n            raise NameError('logistic_regressionはパラメータが存在しないのでサポートしていません')\n\n    def objective_random_forest(self, X_train, y_train, X_valid, y_valid):\n        def objective(trial):\n            n_estimators = trial.suggest_int('n_estimators', 10, 300)\n            max_depth = trial.suggest_int('max_depth', 1, 15)\n            _, y_val_pre, _ = md.random_forest('learn', X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, n_estimators=n_estimators, max_depth=max_depth, random_state=0)\n            \n            score = log_loss(y_valid, y_val_pre)\n\n            return score\n        return objective\n\n    def objective_light_gbm(self, X_train, y_train, X_valid, y_valid, categorical_features):\n        def objective(trial):\n            params = {\n            'objective': 'binary',\n            'max_bin': trial.suggest_int('max_bin', 255, 500),\n            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.1),\n            'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n            }\n            _, y_val_pre, _ = md.light_gbm(categorical_features, 'learn', X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, params=params)\n            \n            score = log_loss(y_valid, y_val_pre)\n\n            return score\n        return objective\n\n    def objective_xgboost(self, X_train, y_train, X_valid, y_valid):\n        def objective(trial):\n            params = {'objective': 'reg:squarederror',\n                    'silent':1, \n                    'random_state':0,\n                    'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.2), \n                    'eval_metric': 'rmse',\n            }\n            num_round = trial.suggest_int('num_round', 100, 900)\n            _, y_val_pre, _ = md.xgboost('learn', X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, params=params, num_round=num_round)\n            \n            score = log_loss(y_valid, y_val_pre)\n\n            return score\n        return objective\n\n    def objective_catboost(self, X_train, y_train, X_valid, y_valid, categorical_features):\n        def objective(trial):\n            params = {\n                'depth' : trial.suggest_int('depth', 1, 15),                  # 木の深さ\n                'learning_rate' : trial.suggest_uniform('learning_rate', 0.01, 0.1),       # 学習率\n                'early_stopping_rounds' : trial.suggest_int('early_stopping_rounds', 3, 20),\n                'iterations' : trial.suggest_int('iterations', 50, 500), \n                'custom_loss' :['Accuracy'], \n                'random_seed' :0\n            }\n            _, y_val_pre, _ = md.catboost(categorical_features, 'learn', X_train=X_train, y_train=y_train, X_valid=X_valid, y_valid=y_valid, params=params)\n            \n            score = log_loss(y_valid, y_val_pre)\n\n            return score\n        return objective\n\n    #LogisticRegressionはパラメータがない","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:22.817238Z","iopub.execute_input":"2022-01-17T08:07:22.817594Z","iopub.status.idle":"2022-01-17T08:07:22.838359Z","shell.execute_reply.started":"2022-01-17T08:07:22.817544Z","shell.execute_reply":"2022-01-17T08:07:22.837274Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# アンサンブル","metadata":{}},{"cell_type":"code","source":"from sklearn import ensemble\nimport numpy as np\nimport pandas as pd\n\n#md = Models()\nut = Util()\n\nclass Ensemble():\n\n    def __init__(self) -> None:\n        pass\n\n    def stacking(self, categorical_features, learn_type, fileID=0, X_train=None, y_train=None, X_test=None, fst_lay=['random_forest', 'light_gbm', 'xgboost', 'catboost'], snd_lay='light_gbm', enable_2ndorigx=True):\n        #enable_2ndorigx:二層目にオリジナルの入力データを入力するか\n\n        stack_oof_pred = []\n        stack_pred = []\n        for index, model_name in enumerate(fst_lay):\n            \n            if learn_type=='learn':\n                cv_score, oof_pre, y_sub = md.KFold(categorical_features, model_name, learn_type, fileID=fileID+'0', X_train=X_train, y_train=y_train)\n                stack_oof_pred = oof_pre if index == 0 else np.c_[stack_oof_pred, oof_pre]\n            elif learn_type=='predict':\n                cv_score, oof_pre, y_sub = md.KFold(categorical_features, model_name, learn_type, fileID=fileID+'0', X_test=X_test)\n                stack_pred = y_sub if index == 0 else np.c_[stack_pred, y_sub]\n            else:\n                raise NameError(\"指定されたlearn_typeは存在しません\")\n\n        if enable_2ndorigx:\n            X_train2 =  pd.concat([pd.DataFrame(stack_oof_pred), X_train], axis=1)\n            X_test2 =  pd.concat([pd.DataFrame(stack_pred), X_test], axis=1)\n        else:\n            X_train2 = pd.DataFrame(stack_oof_pred)\n            X_test2 = pd.DataFrame(stack_pred)\n            categorical_features = []\n\n        #二層目\n        if learn_type=='learn':\n            cv_score, oof_pre, y_sub = md.KFold(categorical_features, snd_lay, learn_type, fileID=fileID+'1', X_train=X_train2, y_train=y_train)\n        elif learn_type=='predict':\n            cv_score, oof_pre, y_sub = md.KFold(categorical_features, snd_lay, learn_type, fileID=fileID+'1', X_test=X_test2)\n            y_sub = ut.data_conv(y_sub)\n\n        return cv_score, oof_pre, y_sub\n\n    def mean(self, categorical_features, learn_type, fileID=0, X_train=None, y_train=None, X_test=None, models=['random_forest', 'light_gbm', 'xgboost', 'catboost'], type='mean'):\n        '''\n        type:平均の取り方 \n        mean -> 算術平均\n        hmean -> 調和平均\n        gmean -> 幾何平均\n        '''\n\n        stack_oof_pred = []\n        stack_pred = []\n        for index, model_name in enumerate(models):\n            if learn_type=='learn':\n                cv_score, oof_pre, y_sub = md.KFold(categorical_features, model_name, learn_type, fileID=fileID+'0', X_train=X_train, y_train=y_train)\n                stack_oof_pred = oof_pre if index == 0 else np.c_[stack_oof_pred, oof_pre]\n            elif learn_type=='predict':\n                cv_score, oof_pre, y_sub = md.KFold(categorical_features, model_name, learn_type, fileID=fileID+'0', X_test=X_test)\n                stack_pred = y_sub if index == 0 else np.c_[stack_pred, y_sub]\n            else:\n                raise NameError(\"指定されたlearn_typeは存在しません\")\n\n        if type == 'mean':\n            y_off = np.average(stack_oof_pred, axis=1)\n            y_sub = np.average(stack_pred, axis=1)\n        elif type == 'hmean':\n            from scipy.stats import hmean\n            y_off = hmean(stack_oof_pred, axis = 1)\n            y_sub = hmean(stack_pred, axis = 1)\n        elif type == 'gmean':\n            from scipy.stats.mstats import gmean\n            y_off = gmean(stack_oof_pred, axis = 1)\n            y_sub = gmean(stack_pred, axis = 1)\n        \n        y_off = ut.data_conv(y_off)\n        y_sub = ut.data_conv(y_sub)\n\n        cv_score = ut.accuracy_score(y_train, y_off)\n        \n        return cv_score, oof_pre, y_sub","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:22.840067Z","iopub.execute_input":"2022-01-17T08:07:22.840374Z","iopub.status.idle":"2022-01-17T08:07:22.863310Z","shell.execute_reply.started":"2022-01-17T08:07:22.840325Z","shell.execute_reply":"2022-01-17T08:07:22.861428Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# コントローラー","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nop = Optimizer()\nens = Ensemble()\n\nclass Controller():\n\n    def __init__(self,ID) -> None:\n        self.md = Models(ID)\n        self.ID = str(ID)\n\n    def opt(self, X_train, y_train):\n        print(op.param_opt('light_gbm', X_train, y_train))\n\n    def KFold_learn(self, categorical_features, X_train, y_train, model_name):\n        cv_score, y_val_pre, y_sub = self.md.KFold(categorical_features, model_name, 'learn', fileID=self.ID+'0', X_train=X_train, y_train=y_train)\n\n        print('CV score-----------------------------------',cv_score)\n        #random_forest 0.822635113928818\n        #light_gbm 0.8293829640323895\n        #catboost 0.8204004770573097\n        #logistic_regression 0.6846023476241291\n        #xgboost 0.8192643274119641\n        #dnn 0.8159060950348378s\n        \n        return cv_score\n\n    def KFold_predict(self, categorical_features, X_test, model_name):\n        cv_score, y_val_pre, y_sub = self.md.KFold(categorical_features, model_name, 'predict', fileID=self.ID+'0', X_test=X_test)\n        \n        return y_sub\n\n    def stacking_learn(self, categorical_features, X_train, y_train, fst_lay=['random_forest', 'light_gbm', 'xgboost', 'catboost'], snd_lay='light_gbm', enable_2ndorigx=False):\n        cv_score, _, y_sub = ens.stacking(categorical_features, 'learn', fileID=self.ID, X_train=X_train, y_train=y_train, fst_lay=fst_lay, snd_lay=snd_lay, enable_2ndorigx=enable_2ndorigx)\n\n        print('CV score-----------------------------------',cv_score)\n        #0.8293829640323895 2ndlgtm\n        #0.8237712635741635 2ndrandomforest\n\n    def stacking_predict(self, categorical_features, X_test, fst_lay=['random_forest', 'light_gbm', 'xgboost', 'catboost'], snd_lay='light_gbm', enable_2ndorigx=False):\n        _, _, y_sub = ens.stacking(categorical_features, 'predict', fileID=self.ID, X_test=X_test, fst_lay=fst_lay, snd_lay=snd_lay, enable_2ndorigx=enable_2ndorigx)\n\n        sub = pd.read_csv('input/titanic/gender_submission.csv')\n        sub['Survived'] = y_sub\n        sub.to_csv('submission.csv', index=False)\n        #0.8293829640323895\n\n    def mean_learn(self, categorical_features, learn_type, X_train, y_train, models=['random_forest', 'light_gbm', 'xgboost', 'catboost'], type='mean'):\n        cv_score, _, y_sub = ens.mean(categorical_features, learn_type, fileID=self.ID, X_train=X_train, y_train=y_train, models=models, type=type)\n        #mean:0.8237934904601572 hmean:0.819304152637486 gmean:0.819304152637486\n        print('CV score-----------------------------------',cv_score)\n\n    def mean_predict(self, categorical_features, learn_type, X_test, models=['random_forest', 'light_gbm', 'xgboost', 'catboost'], type='mean'):\n        cv_score, _, y_sub = ens.mean(categorical_features, learn_type, fileID=self.ID, X_test=X_test, models=models, type=type)\n\n        sub = pd.read_csv('input/titanic/gender_submission.csv')\n        sub['Survived'] = y_sub\n        sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:22.866061Z","iopub.execute_input":"2022-01-17T08:07:22.866467Z","iopub.status.idle":"2022-01-17T08:07:22.882285Z","shell.execute_reply.started":"2022-01-17T08:07:22.866425Z","shell.execute_reply":"2022-01-17T08:07:22.881413Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"markdown","source":"教師データ読み込み","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\nseed_everything\n\ndata_folder = \"../input/g-research-crypto-forecasting/\"\n#crypto_df = reduce_mem_usage(pd.read_csv(data_folder + 'train.csv'))\ncrypto_df = pd.read_csv(data_folder + 'train.csv')\n\ntrain_list = list(range(13))\nfor Asset_ID in range(13):#通貨別にデータを作りそれを通貨別でリストにDFを格納\n    #train = reduce_mem_usage(crypto_df[crypto_df[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\"))\n    train = crypto_df[crypto_df[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\")\n    train_list[Asset_ID] = train\ndel crypto_df\ndel train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:22.883848Z","iopub.execute_input":"2022-01-17T08:07:22.884143Z","iopub.status.idle":"2022-01-17T08:07:29.184619Z","shell.execute_reply.started":"2022-01-17T08:07:22.884107Z","shell.execute_reply":"2022-01-17T08:07:29.182200Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30233/3831172440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../input/g-research-crypto-forecasting/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#crypto_df = reduce_mem_usage(pd.read_csv(data_folder + 'train.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcrypto_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."],"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error"}]},{"cell_type":"markdown","source":"## 学習","metadata":{}},{"cell_type":"code","source":"scores = []\nfe = Feature()\nfor Asset_ID in range(13):#通貨別にデータを作りそれを通貨別でリストにDFを格納\n    \n    print('通貨番号',Asset_ID)\n    \n    train_raw = train_list[Asset_ID].copy()\n    y_train = train_raw['Target'].copy()\n    X_train = train_raw.drop('Target', axis=1).copy()\n    \n    y_train.reset_index(drop=True, inplace=True)\n    y_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n    y_train.fillna(method='ffill', inplace=True)\n    y_train.fillna(0, inplace=True)\n    X_train = fe.conv_data(X_train, Asset_ID, train_list, save_fet=False, save_name='feature')\n    #print(train)\n    #print(train_list[1])\n    categorical_features = ['CDL2CROWS']\n    \n    ct = Controller(Asset_ID)\n            \n    cv_score = ct.KFold_learn(categorical_features, X_train, y_train, 'xgboost')\n    scores.append(cv_score)\n    #ct.stacking_learn(categorical_features, X_train, y_train, fst_lay=['dnn', 'light_gbm', 'xgboost'], snd_lay='light_gbm', enable_2ndorigx=False)\n    \n    del train_raw, y_train, X_train, ct\n    gc.collect()\n    \n    print('5',psutil.virtual_memory().percent)\n    \n    \nprint('CV mean-----------------------------'+str(sum(scores)/len(scores)))\n\n#CV score----------------------------------- 0.23738583123946141 light_gbm 0.2578\n#xgboost 0.44045052797107087\n#random forest 微妙　0.15 \n#catboost 0.06","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.185447Z","iopub.status.idle":"2022-01-17T08:07:29.185735Z","shell.execute_reply.started":"2022-01-17T08:07:29.185588Z","shell.execute_reply":"2022-01-17T08:07:29.185605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #del train_raw\n# del X_train, y_train\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.190203Z","iopub.status.idle":"2022-01-17T08:07:29.190591Z","shell.execute_reply.started":"2022-01-17T08:07:29.190405Z","shell.execute_reply":"2022-01-17T08:07:29.190428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del train_list\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.191617Z","iopub.status.idle":"2022-01-17T08:07:29.191999Z","shell.execute_reply.started":"2022-01-17T08:07:29.191815Z","shell.execute_reply":"2022-01-17T08:07:29.191840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n\n# print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n# print(\" ------------------------------------ \")\n# for var_name in dir():\n#     if not var_name.startswith(\"_\"):\n#         print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.193653Z","iopub.status.idle":"2022-01-17T08:07:29.194261Z","shell.execute_reply.started":"2022-01-17T08:07:29.194015Z","shell.execute_reply":"2022-01-17T08:07:29.194041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_list[0].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.195315Z","iopub.status.idle":"2022-01-17T08:07:29.196142Z","shell.execute_reply.started":"2022-01-17T08:07:29.195880Z","shell.execute_reply":"2022-01-17T08:07:29.195908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fe.conv_data(train_list[0], save_fet=False, save_name='feature')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.197550Z","iopub.status.idle":"2022-01-17T08:07:29.197963Z","shell.execute_reply.started":"2022-01-17T08:07:29.197740Z","shell.execute_reply":"2022-01-17T08:07:29.197763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## predict","metadata":{}},{"cell_type":"code","source":"supplemental_df = pd.read_csv(data_folder + 'supplemental_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:34.877273Z","iopub.execute_input":"2022-01-17T08:07:34.877728Z","iopub.status.idle":"2022-01-17T08:07:37.913812Z","shell.execute_reply.started":"2022-01-17T08:07:34.877684Z","shell.execute_reply":"2022-01-17T08:07:37.912982Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_list = list(range(13))\nfor Asset_ID in range(13):#通貨別にデータを作りそれを通貨別でリストにDFを格納\n    supplemental_train = supplemental_df[supplemental_df[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\")\n    if len(supplemental_train) > 26000:#30000\n        #supplemental_df.drop(supplemental_df.index[-26000:], inplace=True)\n        supplemental_train = supplemental_train.iloc[-26000:,:]\n    test_list[Asset_ID] = supplemental_train","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:37.915436Z","iopub.execute_input":"2022-01-17T08:07:37.915749Z","iopub.status.idle":"2022-01-17T08:07:38.263851Z","shell.execute_reply.started":"2022-01-17T08:07:37.915718Z","shell.execute_reply":"2022-01-17T08:07:38.263049Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gresearch_crypto\n#以下二つは1セッションで一度しか実行できない\nenv = gresearch_crypto.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:38.265523Z","iopub.execute_input":"2022-01-17T08:07:38.266027Z","iopub.status.idle":"2022-01-17T08:07:38.278175Z","shell.execute_reply.started":"2022-01-17T08:07:38.265977Z","shell.execute_reply":"2022-01-17T08:07:38.277238Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import time\nfe = Feature()\nctlist = []\nfor Asset_ID in range(13):\n    ct = Controller(Asset_ID)\n    ctlist.append(ct)\nfor i, (df_test, df_pred) in enumerate(iter_test):\n    start1 = time.time()\n    for Asset_ID in range(13):\n        test_raw = df_test[df_test[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\")\n        test = pd.concat([test_list[Asset_ID], test_raw], sort=False)\n        if len(test) > 26000:#30000\n            #test.drop(test.index[-26000:], inplace=True)\n            test = test.iloc[-26000:,:]\n        test_list[Asset_ID] = test.copy()\n    print (\"1elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n    for Asset_ID in range(13):\n        start = time.time()\n        print('通貨番号',Asset_ID)\n\n        test_raw = test_list[Asset_ID].copy()\n        \n        #print(test_raw)\n        \n        row_id = test_raw.iat[-1, 9]\n        print('row_id :',row_id)\n        X_test = test_raw.drop(['Target','row_id'], axis=1).copy()\n        print (\"2elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n        start = time.time()\n        X_test = fe.conv_data(X_test, Asset_ID, test_list, save_fet=False, save_name='feature', save_mem=False, test=True).iloc[-1:]\n        categorical_features = ['CDL2CROWS']\n        print (\"3elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n        start = time.time()\n        ct = ctlist[Asset_ID]\n        y_sub = ct.KFold_predict(categorical_features, X_test, 'xgboost')[-1]\n        #y_sub = ct.stacking_predict(categorical_features, X_test)\n        print (\"4elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n        \n        print('pred :',y_sub)\n        #print(df_pred)\n        #print(df_pred['row_id'] == row_id)\n        \n        df_pred.loc[df_pred['row_id'] == row_id, 'Target'] = y_sub\n    \n    #print(df_pred)\n    print (\"elapsed_time:{0}\".format(time.time() - start1) + \"[sec]\")\n    env.predict(df_pred)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:39.579428Z","iopub.execute_input":"2022-01-17T08:07:39.579725Z","iopub.status.idle":"2022-01-17T08:07:48.826852Z","shell.execute_reply.started":"2022-01-17T08:07:39.579679Z","shell.execute_reply":"2022-01-17T08:07:48.826272Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n1elapsed_time:0.04245257377624512[sec]\n通貨番号 0\nrow_id : 2.0\n2elapsed_time:0.0026099681854248047[sec]\n1.0elapsed_time:0.01214909553527832[sec]\n1.1elapsed_time:0.009057044982910156[sec]\n1.2elapsed_time:0.017085790634155273[sec]\n1.3elapsed_time:0.0018231868743896484[sec]\n1.4elapsed_time:0.0014662742614746094[sec]\n3elapsed_time:0.04572272300720215[sec]\n4elapsed_time:0.3429715633392334[sec]\npred : 0.16936742\n通貨番号 1\nrow_id : 3.0\n2elapsed_time:0.002687215805053711[sec]\n1.0elapsed_time:0.014374732971191406[sec]\n1.1elapsed_time:0.008491992950439453[sec]\n1.2elapsed_time:0.01434636116027832[sec]\n1.3elapsed_time:0.0011775493621826172[sec]\n1.4elapsed_time:0.0011112689971923828[sec]\n3elapsed_time:0.043028831481933594[sec]\n4elapsed_time:0.021122217178344727[sec]\npred : 0.018645097\n通貨番号 2\nrow_id : 1.0\n2elapsed_time:0.002485990524291992[sec]\n1.0elapsed_time:0.012256383895874023[sec]\n1.1elapsed_time:0.00809478759765625[sec]\n1.2elapsed_time:0.013529539108276367[sec]\n1.3elapsed_time:0.0010552406311035156[sec]\n1.4elapsed_time:0.0011980533599853516[sec]\n3elapsed_time:0.039621829986572266[sec]\n4elapsed_time:0.020150423049926758[sec]\npred : 0.029690584\n通貨番号 3\nrow_id : 0.0\n2elapsed_time:0.0021169185638427734[sec]\n1.0elapsed_time:0.012429952621459961[sec]\n1.1elapsed_time:0.007924318313598633[sec]\n1.2elapsed_time:0.014381885528564453[sec]\n1.3elapsed_time:0.0010044574737548828[sec]\n1.4elapsed_time:0.0010788440704345703[sec]\n3elapsed_time:0.04033803939819336[sec]\n4elapsed_time:0.0206754207611084[sec]\npred : -0.0010340135\n通貨番号 4\nrow_id : 4.0\n2elapsed_time:0.0020172595977783203[sec]\n1.0elapsed_time:0.01443791389465332[sec]\n1.1elapsed_time:0.008060932159423828[sec]\n1.2elapsed_time:0.013387680053710938[sec]\n1.3elapsed_time:0.0009639263153076172[sec]\n1.4elapsed_time:0.0011997222900390625[sec]\n3elapsed_time:0.042179107666015625[sec]\n4elapsed_time:0.020281314849853516[sec]\npred : 0.04037709\n通貨番号 5\nrow_id : 5.0\n2elapsed_time:0.0019254684448242188[sec]\n1.0elapsed_time:0.012934207916259766[sec]\n1.1elapsed_time:0.008473396301269531[sec]\n1.2elapsed_time:0.013446331024169922[sec]\n1.3elapsed_time:0.0010025501251220703[sec]\n1.4elapsed_time:0.0010783672332763672[sec]\n3elapsed_time:0.040850162506103516[sec]\n4elapsed_time:0.020250320434570312[sec]\npred : -0.0067067295\n通貨番号 6\nrow_id : 7.0\n2elapsed_time:0.002169370651245117[sec]\n1.0elapsed_time:0.012859821319580078[sec]\n1.1elapsed_time:0.00867319107055664[sec]\n1.2elapsed_time:0.014244556427001953[sec]\n1.3elapsed_time:0.0012176036834716797[sec]\n1.4elapsed_time:0.0011391639709472656[sec]\n3elapsed_time:0.041863441467285156[sec]\n4elapsed_time:0.021108627319335938[sec]\npred : 0.015258554\n通貨番号 7\nrow_id : 6.0\n2elapsed_time:0.0024018287658691406[sec]\n1.0elapsed_time:0.012615442276000977[sec]\n1.1elapsed_time:0.009098052978515625[sec]\n1.2elapsed_time:0.015238285064697266[sec]\n1.3elapsed_time:0.0012295246124267578[sec]\n1.4elapsed_time:0.0010833740234375[sec]\n3elapsed_time:0.04307889938354492[sec]\n4elapsed_time:0.020727157592773438[sec]\npred : -0.046636082\n通貨番号 8\nrow_id : 8.0\n2elapsed_time:0.0020253658294677734[sec]\n1.0elapsed_time:0.012305974960327148[sec]\n1.1elapsed_time:0.008498430252075195[sec]\n1.2elapsed_time:0.013866186141967773[sec]\n1.3elapsed_time:0.0012776851654052734[sec]\n1.4elapsed_time:0.0010845661163330078[sec]\n3elapsed_time:0.04103279113769531[sec]\n4elapsed_time:0.019745826721191406[sec]\npred : 0.0349698\n通貨番号 9\nrow_id : 9.0\n2elapsed_time:0.002000570297241211[sec]\n1.0elapsed_time:0.013651609420776367[sec]\n1.1elapsed_time:0.007470369338989258[sec]\n1.2elapsed_time:0.01408076286315918[sec]\n1.3elapsed_time:0.001062154769897461[sec]\n1.4elapsed_time:0.001157999038696289[sec]\n3elapsed_time:0.04089617729187012[sec]\n4elapsed_time:0.02023768424987793[sec]\npred : 0.023157567\n通貨番号 10\nrow_id : 10.0\n2elapsed_time:0.0019180774688720703[sec]\n1.0elapsed_time:0.012341737747192383[sec]\n1.1elapsed_time:0.007876873016357422[sec]\n1.2elapsed_time:0.01633739471435547[sec]\n1.3elapsed_time:0.001230478286743164[sec]\n1.4elapsed_time:0.001077890396118164[sec]\n3elapsed_time:0.042171478271484375[sec]\n4elapsed_time:0.037564754486083984[sec]\npred : -0.0018474115\n通貨番号 11\nrow_id : 13.0\n2elapsed_time:0.0026557445526123047[sec]\n1.0elapsed_time:0.021892309188842773[sec]\n1.1elapsed_time:0.018636226654052734[sec]\n1.2elapsed_time:0.02690434455871582[sec]\n1.3elapsed_time:0.0009975433349609375[sec]\n1.4elapsed_time:0.0011391639709472656[sec]\n3elapsed_time:0.0741274356842041[sec]\n4elapsed_time:0.05178570747375488[sec]\npred : -0.03812665\n通貨番号 12\nrow_id : 12.0\n2elapsed_time:0.0064754486083984375[sec]\n1.0elapsed_time:0.02111196517944336[sec]\n1.1elapsed_time:0.01566338539123535[sec]\n1.2elapsed_time:0.0230710506439209[sec]\n1.3elapsed_time:0.0036363601684570312[sec]\n1.4elapsed_time:0.001968860626220703[sec]\n3elapsed_time:0.0720829963684082[sec]\n4elapsed_time:0.10049104690551758[sec]\npred : 0.008114824\nelapsed_time:0.10186123847961426[sec]\n1elapsed_time:0.0532832145690918[sec]\n通貨番号 0\nrow_id : 16.0\n2elapsed_time:0.002849102020263672[sec]\n1.0elapsed_time:0.01686382293701172[sec]\n1.1elapsed_time:0.013857841491699219[sec]\n1.2elapsed_time:0.021847963333129883[sec]\n1.3elapsed_time:0.001375436782836914[sec]\n1.4elapsed_time:0.001552581787109375[sec]\n3elapsed_time:0.06458210945129395[sec]\n4elapsed_time:0.022199392318725586[sec]\npred : 0.1769685\n通貨番号 1\nrow_id : 17.0\n2elapsed_time:0.002526998519897461[sec]\n1.0elapsed_time:0.014841556549072266[sec]\n1.1elapsed_time:0.010855436325073242[sec]\n1.2elapsed_time:0.021289348602294922[sec]\n1.3elapsed_time:0.0013012886047363281[sec]\n1.4elapsed_time:0.0014424324035644531[sec]\n3elapsed_time:0.05462932586669922[sec]\n4elapsed_time:0.02744150161743164[sec]\npred : 0.01818425\n通貨番号 2\nrow_id : 15.0\n2elapsed_time:0.002096891403198242[sec]\n1.0elapsed_time:0.0227358341217041[sec]\n1.1elapsed_time:0.012194633483886719[sec]\n1.2elapsed_time:0.02298712730407715[sec]\n1.3elapsed_time:0.001360177993774414[sec]\n1.4elapsed_time:0.0014047622680664062[sec]\n3elapsed_time:0.0649712085723877[sec]\n4elapsed_time:0.048845529556274414[sec]\npred : 0.023922663\n通貨番号 3\nrow_id : 14.0\n2elapsed_time:0.002492666244506836[sec]\n1.0elapsed_time:0.012944459915161133[sec]\n1.1elapsed_time:0.008160591125488281[sec]\n1.2elapsed_time:0.014484882354736328[sec]\n1.3elapsed_time:0.0013895034790039062[sec]\n1.4elapsed_time:0.0011661052703857422[sec]\n3elapsed_time:0.04204869270324707[sec]\n4elapsed_time:0.019329309463500977[sec]\npred : -0.001833694\n通貨番号 4\nrow_id : 18.0\n2elapsed_time:0.0021550655364990234[sec]\n1.0elapsed_time:0.013213634490966797[sec]\n1.1elapsed_time:0.008479833602905273[sec]\n1.2elapsed_time:0.014954566955566406[sec]\n1.3elapsed_time:0.001169443130493164[sec]\n1.4elapsed_time:0.0011858940124511719[sec]\n3elapsed_time:0.04256105422973633[sec]\n4elapsed_time:0.01892995834350586[sec]\npred : 0.049575083\n通貨番号 5\nrow_id : 19.0\n2elapsed_time:0.0028977394104003906[sec]\n1.0elapsed_time:0.014124870300292969[sec]\n1.1elapsed_time:0.00893402099609375[sec]\n1.2elapsed_time:0.014670372009277344[sec]\n1.3elapsed_time:0.0011010169982910156[sec]\n1.4elapsed_time:0.0015645027160644531[sec]\n3elapsed_time:0.044048309326171875[sec]\n4elapsed_time:0.019629955291748047[sec]\npred : -0.008514516\n通貨番号 6\nrow_id : 21.0\n2elapsed_time:0.0021326541900634766[sec]\n1.0elapsed_time:0.012787818908691406[sec]\n1.1elapsed_time:0.00787663459777832[sec]\n1.2elapsed_time:0.014801025390625[sec]\n1.3elapsed_time:0.001100778579711914[sec]\n1.4elapsed_time:0.0011544227600097656[sec]\n3elapsed_time:0.04128289222717285[sec]\n4elapsed_time:0.019530057907104492[sec]\npred : 0.016049411\n通貨番号 7\nrow_id : 20.0\n2elapsed_time:0.0021800994873046875[sec]\n1.0elapsed_time:0.012499332427978516[sec]\n1.1elapsed_time:0.009678125381469727[sec]\n1.2elapsed_time:0.014112472534179688[sec]\n1.3elapsed_time:0.0010035037994384766[sec]\n1.4elapsed_time:0.0010883808135986328[sec]\n3elapsed_time:0.04203343391418457[sec]\n4elapsed_time:0.018776893615722656[sec]\npred : -0.057386953\n通貨番号 8\nrow_id : 22.0\n2elapsed_time:0.0019910335540771484[sec]\n1.0elapsed_time:0.01220393180847168[sec]\n1.1elapsed_time:0.008592605590820312[sec]\n1.2elapsed_time:0.015454292297363281[sec]\n1.3elapsed_time:0.001066446304321289[sec]\n1.4elapsed_time:0.0011925697326660156[sec]\n3elapsed_time:0.042128801345825195[sec]\n4elapsed_time:0.019550085067749023[sec]\npred : 0.03593583\n通貨番号 9\nrow_id : 23.0\n2elapsed_time:0.0021507740020751953[sec]\n1.0elapsed_time:0.012793779373168945[sec]\n1.1elapsed_time:0.007820606231689453[sec]\n1.2elapsed_time:0.014668703079223633[sec]\n1.3elapsed_time:0.0010936260223388672[sec]\n1.4elapsed_time:0.0011289119720458984[sec]\n3elapsed_time:0.041205406188964844[sec]\n4elapsed_time:0.01918649673461914[sec]\npred : 0.023499973\n通貨番号 10\nrow_id : 24.0\n2elapsed_time:0.001964092254638672[sec]\n1.0elapsed_time:0.01348423957824707[sec]\n1.1elapsed_time:0.008799076080322266[sec]\n1.2elapsed_time:0.014810323715209961[sec]\n1.3elapsed_time:0.0010406970977783203[sec]\n1.4elapsed_time:0.001169443130493164[sec]\n3elapsed_time:0.04324221611022949[sec]\n4elapsed_time:0.018733739852905273[sec]\npred : -0.0020349547\n通貨番号 11\nrow_id : 27.0\n2elapsed_time:0.0022118091583251953[sec]\n1.0elapsed_time:0.012039422988891602[sec]\n1.1elapsed_time:0.007714986801147461[sec]\n1.2elapsed_time:0.01429605484008789[sec]\n1.3elapsed_time:0.001363992691040039[sec]\n1.4elapsed_time:0.0011968612670898438[sec]\n3elapsed_time:0.03992748260498047[sec]\n4elapsed_time:0.022155046463012695[sec]\npred : -0.028354673\n通貨番号 12\nrow_id : 26.0\n2elapsed_time:0.0024280548095703125[sec]\n1.0elapsed_time:0.012555599212646484[sec]\n1.1elapsed_time:0.007906436920166016[sec]\n1.2elapsed_time:0.014693975448608398[sec]\n1.3elapsed_time:0.0011043548583984375[sec]\n1.4elapsed_time:0.001188516616821289[sec]\n3elapsed_time:0.041820526123046875[sec]\n4elapsed_time:0.019993066787719727[sec]\npred : 0.0058452655\nelapsed_time:0.021249771118164062[sec]\n1elapsed_time:0.042185068130493164[sec]\n通貨番号 0\nrow_id : 30.0\n2elapsed_time:0.002566099166870117[sec]\n1.0elapsed_time:0.011974811553955078[sec]\n1.1elapsed_time:0.008238554000854492[sec]\n1.2elapsed_time:0.014434576034545898[sec]\n1.3elapsed_time:0.0011570453643798828[sec]\n1.4elapsed_time:0.0011408329010009766[sec]\n3elapsed_time:0.040585994720458984[sec]\n4elapsed_time:0.020576000213623047[sec]\npred : 0.17767856\n通貨番号 1\nrow_id : 31.0\n2elapsed_time:0.0025017261505126953[sec]\n1.0elapsed_time:0.012590408325195312[sec]\n1.1elapsed_time:0.008048772811889648[sec]\n1.2elapsed_time:0.016438961029052734[sec]\n1.3elapsed_time:0.0014426708221435547[sec]\n1.4elapsed_time:0.0011553764343261719[sec]\n3elapsed_time:0.04354381561279297[sec]\n4elapsed_time:0.018822669982910156[sec]\npred : 0.0195452\n通貨番号 2\nrow_id : 29.0\n2elapsed_time:0.002422809600830078[sec]\n1.0elapsed_time:0.012768745422363281[sec]\n1.1elapsed_time:0.008344173431396484[sec]\n1.2elapsed_time:0.014178991317749023[sec]\n1.3elapsed_time:0.0012791156768798828[sec]\n1.4elapsed_time:0.001096963882446289[sec]\n3elapsed_time:0.041368961334228516[sec]\n4elapsed_time:0.01861858367919922[sec]\npred : 0.026944539\n通貨番号 3\nrow_id : 28.0\n2elapsed_time:0.002034425735473633[sec]\n1.0elapsed_time:0.012232303619384766[sec]\n1.1elapsed_time:0.008293628692626953[sec]\n1.2elapsed_time:0.014278411865234375[sec]\n1.3elapsed_time:0.0011138916015625[sec]\n1.4elapsed_time:0.0012178421020507812[sec]\n3elapsed_time:0.04078102111816406[sec]\n4elapsed_time:0.01893162727355957[sec]\npred : -0.005098503\n通貨番号 4\nrow_id : 32.0\n2elapsed_time:0.002132892608642578[sec]\n1.0elapsed_time:0.012604713439941406[sec]\n1.1elapsed_time:0.008825540542602539[sec]\n1.2elapsed_time:0.01475667953491211[sec]\n1.3elapsed_time:0.001277923583984375[sec]\n1.4elapsed_time:0.0014119148254394531[sec]\n3elapsed_time:0.0423121452331543[sec]\n4elapsed_time:0.02086925506591797[sec]\npred : 0.04529303\n通貨番号 5\nrow_id : 33.0\n2elapsed_time:0.0020787715911865234[sec]\n1.0elapsed_time:0.012790918350219727[sec]\n1.1elapsed_time:0.008339881896972656[sec]\n1.2elapsed_time:0.013671398162841797[sec]\n1.3elapsed_time:0.0010328292846679688[sec]\n1.4elapsed_time:0.0010874271392822266[sec]\n3elapsed_time:0.04050397872924805[sec]\n4elapsed_time:0.01848578453063965[sec]\npred : -0.0148682315\n通貨番号 6\nrow_id : 35.0\n2elapsed_time:0.002004861831665039[sec]\n1.0elapsed_time:0.011823892593383789[sec]\n1.1elapsed_time:0.008065938949584961[sec]\n1.2elapsed_time:0.013914823532104492[sec]\n1.3elapsed_time:0.0010182857513427734[sec]\n1.4elapsed_time:0.0010223388671875[sec]\n3elapsed_time:0.03974008560180664[sec]\n4elapsed_time:0.01867198944091797[sec]\npred : 0.015289981\n通貨番号 7\nrow_id : 34.0\n2elapsed_time:0.0020525455474853516[sec]\n1.0elapsed_time:0.012542724609375[sec]\n1.1elapsed_time:0.008207082748413086[sec]\n1.2elapsed_time:0.014282703399658203[sec]\n1.3elapsed_time:0.0012135505676269531[sec]\n1.4elapsed_time:0.001157522201538086[sec]\n3elapsed_time:0.0409245491027832[sec]\n4elapsed_time:0.019382953643798828[sec]\npred : -0.0523659\n通貨番号 8\nrow_id : 36.0\n2elapsed_time:0.0021715164184570312[sec]\n1.0elapsed_time:0.013663053512573242[sec]\n1.1elapsed_time:0.008483409881591797[sec]\n1.2elapsed_time:0.01392364501953125[sec]\n1.3elapsed_time:0.0011188983917236328[sec]\n1.4elapsed_time:0.001247406005859375[sec]\n3elapsed_time:0.042061805725097656[sec]\n4elapsed_time:0.01903843879699707[sec]\npred : 0.03653069\n通貨番号 9\nrow_id : 37.0\n2elapsed_time:0.0020592212677001953[sec]\n1.0elapsed_time:0.012241840362548828[sec]\n1.1elapsed_time:0.008146047592163086[sec]\n1.2elapsed_time:0.013724327087402344[sec]\n1.3elapsed_time:0.0012576580047607422[sec]\n1.4elapsed_time:0.0011532306671142578[sec]\n3elapsed_time:0.04033708572387695[sec]\n4elapsed_time:0.01859140396118164[sec]\npred : 0.026146617\n通貨番号 10\nrow_id : 38.0\n2elapsed_time:0.0020585060119628906[sec]\n1.0elapsed_time:0.012318611145019531[sec]\n1.1elapsed_time:0.008174896240234375[sec]\n1.2elapsed_time:0.013273000717163086[sec]\n1.3elapsed_time:0.0010120868682861328[sec]\n1.4elapsed_time:0.0010991096496582031[sec]\n3elapsed_time:0.03960418701171875[sec]\n4elapsed_time:0.018885135650634766[sec]\npred : -0.007315367\n通貨番号 11\nrow_id : 41.0\n2elapsed_time:0.002198934555053711[sec]\n1.0elapsed_time:0.012424468994140625[sec]\n1.1elapsed_time:0.008177757263183594[sec]\n1.2elapsed_time:0.016554594039916992[sec]\n1.3elapsed_time:0.0011081695556640625[sec]\n1.4elapsed_time:0.0011887550354003906[sec]\n3elapsed_time:0.0438692569732666[sec]\n4elapsed_time:0.019311189651489258[sec]\npred : -0.049100585\n通貨番号 12\nrow_id : 40.0\n2elapsed_time:0.0020787715911865234[sec]\n1.0elapsed_time:0.012207746505737305[sec]\n1.1elapsed_time:0.008584022521972656[sec]\n1.2elapsed_time:0.01558232307434082[sec]\n1.3elapsed_time:0.0010445117950439453[sec]\n1.4elapsed_time:0.0012154579162597656[sec]\n3elapsed_time:0.042565107345581055[sec]\n4elapsed_time:0.01951885223388672[sec]\npred : 0.0024818005\nelapsed_time:0.0206301212310791[sec]\n1elapsed_time:0.04076647758483887[sec]\n通貨番号 0\nrow_id : 44.0\n2elapsed_time:0.002501964569091797[sec]\n1.0elapsed_time:0.012099981307983398[sec]\n1.1elapsed_time:0.007878780364990234[sec]\n1.2elapsed_time:0.014556884765625[sec]\n1.3elapsed_time:0.0010979175567626953[sec]\n1.4elapsed_time:0.0015680789947509766[sec]\n3elapsed_time:0.040524959564208984[sec]\n4elapsed_time:0.020505189895629883[sec]\npred : 0.17973328\n通貨番号 1\nrow_id : 45.0\n2elapsed_time:0.0025696754455566406[sec]\n1.0elapsed_time:0.013891220092773438[sec]\n1.1elapsed_time:0.008392095565795898[sec]\n1.2elapsed_time:0.015170097351074219[sec]\n1.3elapsed_time:0.0014030933380126953[sec]\n1.4elapsed_time:0.0011944770812988281[sec]\n3elapsed_time:0.044091224670410156[sec]\n4elapsed_time:0.020653724670410156[sec]\npred : 0.019036828\n通貨番号 2\nrow_id : 43.0\n2elapsed_time:0.0023584365844726562[sec]\n1.0elapsed_time:0.0133056640625[sec]\n1.1elapsed_time:0.008359193801879883[sec]\n1.2elapsed_time:0.01417231559753418[sec]\n1.3elapsed_time:0.0010809898376464844[sec]\n1.4elapsed_time:0.0011670589447021484[sec]\n3elapsed_time:0.041899919509887695[sec]\n4elapsed_time:0.02056598663330078[sec]\npred : 0.024695544\n通貨番号 3\nrow_id : 42.0\n2elapsed_time:0.002146005630493164[sec]\n1.0elapsed_time:0.012141704559326172[sec]\n1.1elapsed_time:0.007890462875366211[sec]\n1.2elapsed_time:0.013982772827148438[sec]\n1.3elapsed_time:0.0011005401611328125[sec]\n1.4elapsed_time:0.0011856555938720703[sec]\n3elapsed_time:0.03975176811218262[sec]\n4elapsed_time:0.019852876663208008[sec]\npred : -0.0034728134\n通貨番号 4\nrow_id : 46.0\n2elapsed_time:0.0022029876708984375[sec]\n1.0elapsed_time:0.012194633483886719[sec]\n1.1elapsed_time:0.01185917854309082[sec]\n1.2elapsed_time:0.013962745666503906[sec]\n1.3elapsed_time:0.0010373592376708984[sec]\n1.4elapsed_time:0.001116037368774414[sec]\n3elapsed_time:0.04387354850769043[sec]\n4elapsed_time:0.018801450729370117[sec]\npred : 0.04861703\n通貨番号 5\nrow_id : 47.0\n2elapsed_time:0.0020651817321777344[sec]\n1.0elapsed_time:0.012438058853149414[sec]\n1.1elapsed_time:0.008436441421508789[sec]\n1.2elapsed_time:0.013996601104736328[sec]\n1.3elapsed_time:0.0011112689971923828[sec]\n1.4elapsed_time:0.0011315345764160156[sec]\n3elapsed_time:0.040400028228759766[sec]\n4elapsed_time:0.01859307289123535[sec]\npred : -0.007135467\n通貨番号 6\nrow_id : 49.0\n2elapsed_time:0.002170562744140625[sec]\n1.0elapsed_time:0.012485742568969727[sec]\n1.1elapsed_time:0.008266448974609375[sec]\n1.2elapsed_time:0.015706539154052734[sec]\n1.3elapsed_time:0.0015211105346679688[sec]\n1.4elapsed_time:0.0014913082122802734[sec]\n3elapsed_time:0.0429835319519043[sec]\n4elapsed_time:0.018569469451904297[sec]\npred : 0.014840125\n通貨番号 7\nrow_id : 48.0\n2elapsed_time:0.0023419857025146484[sec]\n1.0elapsed_time:0.012506246566772461[sec]\n1.1elapsed_time:0.008195161819458008[sec]\n1.2elapsed_time:0.01580524444580078[sec]\n1.3elapsed_time:0.001321554183959961[sec]\n1.4elapsed_time:0.0014896392822265625[sec]\n3elapsed_time:0.042977333068847656[sec]\n4elapsed_time:0.01814579963684082[sec]\npred : -0.0519943\n通貨番号 8\nrow_id : 50.0\n2elapsed_time:0.0021088123321533203[sec]\n1.0elapsed_time:0.01254892349243164[sec]\n1.1elapsed_time:0.008396148681640625[sec]\n1.2elapsed_time:0.013571023941040039[sec]\n1.3elapsed_time:0.001219034194946289[sec]\n1.4elapsed_time:0.0011091232299804688[sec]\n3elapsed_time:0.040287017822265625[sec]\n4elapsed_time:0.018694400787353516[sec]\npred : 0.039465383\n通貨番号 9\nrow_id : 51.0\n2elapsed_time:0.0020890235900878906[sec]\n1.0elapsed_time:0.012144804000854492[sec]\n1.1elapsed_time:0.008040428161621094[sec]\n1.2elapsed_time:0.014177083969116211[sec]\n1.3elapsed_time:0.0010035037994384766[sec]\n1.4elapsed_time:0.0011022090911865234[sec]\n3elapsed_time:0.04001164436340332[sec]\n4elapsed_time:0.019188404083251953[sec]\npred : 0.02420978\n通貨番号 10\nrow_id : 52.0\n2elapsed_time:0.0021936893463134766[sec]\n1.0elapsed_time:0.012833118438720703[sec]\n1.1elapsed_time:0.008245706558227539[sec]\n1.2elapsed_time:0.013791561126708984[sec]\n1.3elapsed_time:0.0010018348693847656[sec]\n1.4elapsed_time:0.0011429786682128906[sec]\n3elapsed_time:0.04038190841674805[sec]\n4elapsed_time:0.021349191665649414[sec]\npred : -0.0050577205\n通貨番号 11\nrow_id : 55.0\n2elapsed_time:0.002063274383544922[sec]\n1.0elapsed_time:0.012105464935302734[sec]\n1.1elapsed_time:0.007921218872070312[sec]\n1.2elapsed_time:0.013489961624145508[sec]\n1.3elapsed_time:0.0010218620300292969[sec]\n1.4elapsed_time:0.0011339187622070312[sec]\n3elapsed_time:0.03950333595275879[sec]\n4elapsed_time:0.018996238708496094[sec]\npred : -0.04768793\n通貨番号 12\nrow_id : 54.0\n2elapsed_time:0.0018832683563232422[sec]\n1.0elapsed_time:0.01213693618774414[sec]\n1.1elapsed_time:0.007895231246948242[sec]\n1.2elapsed_time:0.014178276062011719[sec]\n1.3elapsed_time:0.0010197162628173828[sec]\n1.4elapsed_time:0.0010867118835449219[sec]\n3elapsed_time:0.039689064025878906[sec]\n4elapsed_time:0.018670082092285156[sec]\npred : 0.0026852388\nelapsed_time:0.019779443740844727[sec]\n","output_type":"stream"}]},{"cell_type":"code","source":"fe = Feature()\nX_test = test_raw.drop('Target', axis=1).copy()\n\nprint(1)\nX_test = fe.conv_data(X_test, Asset_ID, test_list, save_fet=False, save_name='feature', save_mem=False).iloc[-1:]\nprint(2)\ny_sub = ct.KFold_predict(categorical_features, X_test, 'xgboost')\nprint(2)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.209374Z","iopub.status.idle":"2022-01-17T08:07:29.210101Z","shell.execute_reply.started":"2022-01-17T08:07:29.209844Z","shell.execute_reply":"2022-01-17T08:07:29.209870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_sub[-1]","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.212116Z","iopub.status.idle":"2022-01-17T08:07:29.213046Z","shell.execute_reply.started":"2022-01-17T08:07:29.212799Z","shell.execute_reply":"2022-01-17T08:07:29.212823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# G-Research\n\n* tutrial - [https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition](http://)\n\n# description\n\n* 15分後の価格の変動率を予測する\n* 常に市場の傾向が変動するので、確実な予測モデルを立てるのが難しい(傾向が非定常的)\n* オーバーフィッティングの可能性が高い\n* 通貨間での価格変動の関連性がある。特にビットコインはほかの通貨に影響を与えやすい。\n* 将来、価格がどのように動くかを予測することである。過去の価格の時系列データを学習データとして、価格が上がるか下がるか、またどの程度上がるか、すなわち資産リターンを予測\n\n### Data\n\n#### train.csv\n\n* timestamp: データのUNIX秒。すべて60秒間隔よって、一分ごとにデータが与えられている。\n* Asset_ID: asset_details.csvに書いている通貨IDと結びついており、通貨の種類の識別に使う。 (e.g. Asset_ID = 1 for Bitcoin)\n* Count: 前の一分間で取引された回数\n* Open: 始値 (in USD).\n* High: 前の一分間での最大の価格 (in USD).\n* Low: 前の一分間での最小の価格 (in USD).\n* Close: Close price 終値 (in USD).\n* Volume: 前の一分間の引通貨量(USD)\n* VWAP: 一定期間内での取引価格の、取引量による加重平均\n* Target: 15分前の価格との差をlogでとったもの Residual log-returns for the asset over a 15 minute horizon.\n\n#### asset_details.csv\n\n* Asset_ID 通貨ID\n* Weight 性能評価するときにその通貨の正答率がどのくらい加味されるかの重み\n* Asset_Name IDに結びついている通貨名\n\n\n### 評価方法\n\n\n\n\n\n# task\n\n1. 概要(overview)をしっかり読む\n2. 似ている過去のコンペを探し、参加し基本的な分析を行う\n3. 似たような大会のsolutionを読む\n4. 論文を読んでその分野の進捗を見逃さないようにする\n5. データを分析し安定したCVのモデルを構築する\n6. データ前処理、特徴量エンジニアリングを行い一定のモデルでCVを比較しいい特徴量エンジニアリングを探す\n7. モデルの予測と教師データを比較し分析、予測の難しいデータに対し考察\n8. 分析に基づき高性能なモデルをアンサンブルなどを取り入れて構築\n9.  データ解析、結果分析からより高度な予測の難しいサンプルを解決するモデルを設計\n10. 必要であれば前のステップに戻る\n\n# scores\n\n# else\n\n* supplemental_trainとtrainをくっつけて最後に学習\n* B (billion)\t1,000,000,000","metadata":{}},{"cell_type":"markdown","source":"# 可視化","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.214145Z","iopub.status.idle":"2022-01-17T08:07:29.215017Z","shell.execute_reply.started":"2022-01-17T08:07:29.214759Z","shell.execute_reply":"2022-01-17T08:07:29.214785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_folder = \"../input/g-research-crypto-forecasting/\"\n\n# crypto_df = reduce_mem_usage(pd.read_csv(data_folder + 'train.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.217077Z","iopub.status.idle":"2022-01-17T08:07:29.217667Z","shell.execute_reply.started":"2022-01-17T08:07:29.217420Z","shell.execute_reply":"2022-01-17T08:07:29.217446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_list = []\n# for Asset_ID in range(13):#通貨別にデータを作りそれを通貨別でリストにDFを格納\n#     train = crypto_df[crypto_df[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\")\n#     train = fe.conv_data(train, save_fet=False, save_name='feature')\n#     train_list.append(train)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.219138Z","iopub.status.idle":"2022-01-17T08:07:29.220003Z","shell.execute_reply.started":"2022-01-17T08:07:29.219750Z","shell.execute_reply":"2022-01-17T08:07:29.219777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fe = Feature()\n# for Asset_ID in range(13):#通貨別にデータを作りそれを通貨別でリストにDFを格納\n#     train = train_list[Asset_ID]\n    \n#     categorical_features = ['Embarked', 'Pclass', 'Sex']\n#     y_train = train['Target']\n#     X_train = train.drop('Target', axis=1)\n    \n#     #ct = Controller(Asset_ID)\n#     #ct.stacking_learn(categorical_features, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.221147Z","iopub.status.idle":"2022-01-17T08:07:29.221603Z","shell.execute_reply.started":"2022-01-17T08:07:29.221365Z","shell.execute_reply":"2022-01-17T08:07:29.221388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gresearch_crypto\n# #以下二つは1セッションで一度しか実行できない\n# env = gresearch_crypto.make_env()   # initialize the environment\n# iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.222939Z","iopub.status.idle":"2022-01-17T08:07:29.223416Z","shell.execute_reply.started":"2022-01-17T08:07:29.223163Z","shell.execute_reply":"2022-01-17T08:07:29.223187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for (test_df, sample_prediction_df) in iter_test:\n    \n#     for Asset_ID in df_test.Asset_ID.unique():\n#         df_test = df_test[df_test[\"Asset_ID\"]==Asset_ID].set_index(\"timestamp\")\n        \n#         test = fe.conv_data(test, save_fet=False, save_name='feature')\n\n#         categorical_features = ['Embarked', 'Pclass', 'Sex']\n#         y_train = train['Target']\n        \n#         ct = Controller(Asset_ID)\n#         ct.stacking_predict(categorical_features, X_test)\n    \n#     #testと教師データを結合して特徴量を作る\n    \n#     sample_prediction_df['Target'] = 0  # make your predictions here\n#     env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.224733Z","iopub.status.idle":"2022-01-17T08:07:29.225379Z","shell.execute_reply.started":"2022-01-17T08:07:29.225116Z","shell.execute_reply":"2022-01-17T08:07:29.225142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for (test_df, sample_prediction_df) in iter_test:\n#     sample_prediction_df['Target'] = 0\n#     env.predict(sample_prediction_df)\n#     print(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.226612Z","iopub.status.idle":"2022-01-17T08:07:29.227205Z","shell.execute_reply.started":"2022-01-17T08:07:29.226969Z","shell.execute_reply":"2022-01-17T08:07:29.226993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_folder = \"../input/g-research-crypto-forecasting/\"\n# crypto_df = pd.read_csv(data_folder + 'supplemental_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.228328Z","iopub.status.idle":"2022-01-17T08:07:29.229052Z","shell.execute_reply.started":"2022-01-17T08:07:29.228795Z","shell.execute_reply":"2022-01-17T08:07:29.228821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas_profiling\n\n# train_list[0].profile_report()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.231655Z","iopub.status.idle":"2022-01-17T08:07:29.232413Z","shell.execute_reply.started":"2022-01-17T08:07:29.232151Z","shell.execute_reply":"2022-01-17T08:07:29.232177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# feature optimizer","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# data_folder = \"../input/g-research-crypto-forecasting/\"\n# crypto_df = pd.read_csv(data_folder + 'train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.233751Z","iopub.status.idle":"2022-01-17T08:07:29.234487Z","shell.execute_reply.started":"2022-01-17T08:07:29.234228Z","shell.execute_reply":"2022-01-17T08:07:29.234254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n# import talib\n\n# price = np.array(crypto_df['Close'])\n# returns = np.array(crypto_df['Close'].shift(-15)) - price\n# #returns = np.array(crypto_df['Target'])\n\n# #ROCP {'timeperiod': 6} best param -0.0005372071418046449 best score\n# #MOM {'timeperiod': 127} best param -0.001971999282000135 best score\n# #RSI -0.0009095762807234701 3\n# #EMA {'timeperiod': 11} best param -0.00034526380519110374 best score\n\n# def objective(trial):\n#     timeperiod = trial.suggest_int('timeperiod', 2, 240)\n    \n#     df = talib.ROCP(price, timeperiod=timeperiod)\n#     returns_new = returns[~np.isnan(df)]\n#     df_new = df[~np.isnan(df)]\n#     returns_last = returns_new[~np.isnan(returns_new)]\n#     df_new = df_new[~np.isnan(returns_new)]\n#     ic = get_ic(df_new, returns_last)\n#     print(ic, timeperiod)\n#     return -abs(ic)\n\n# def get_ic(x, returns, normalize=True) -> float:\n#     \"\"\"\n#     :param np.ndarray x: 指標\n#     :param np.ndarray returns: リターン\n#     :param bool normalize: x をスケーリングするかどうか\n#     \"\"\"\n#     assert(len(x) == len(returns))\n#     x = (x - x.mean()) / x.std() if normalize else x\n#     returns = (returns - returns.mean()) / returns.std() if normalize else returns\n#     ic = np.corrcoef(x, returns)[0, 1]\n\n#     return ic\n\n# study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n# study.optimize(objective, n_trials=100)\n# print(study.best_params,'best param')\n# print(study.best_value,'best score')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T08:07:29.235765Z","iopub.status.idle":"2022-01-17T08:07:29.236612Z","shell.execute_reply.started":"2022-01-17T08:07:29.236379Z","shell.execute_reply":"2022-01-17T08:07:29.236404Z"},"trusted":true},"execution_count":null,"outputs":[]}]}